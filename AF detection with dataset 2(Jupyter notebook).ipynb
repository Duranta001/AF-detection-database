{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2cb53bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import pathlib\n",
    "from scipy.io import loadmat\n",
    "import pandas as pd\n",
    "import pywt\n",
    "from scipy.signal import find_peaks,peak_widths\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde769b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cut all the QRS wave and use to classify\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ce88ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = 'New_more'\n",
    "data_dir = pathlib.Path(data)\n",
    "data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9deb82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {\n",
    "    'Normal': list(data_dir.glob('Normal/*')),\n",
    "    'AF': list(data_dir.glob('AF/*'))\n",
    "}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af89e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lavel_dict = {\n",
    "    'Normal': 0,\n",
    "    'AF': 1\n",
    "}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f962d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5ab3ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c460f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75dabc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "y = []\n",
    "for lavel, datas in data_dict.items():\n",
    "    for sig in datas:\n",
    "        data = np.load(str(sig))\n",
    "        Data=data\n",
    "        dataset.append(Data)\n",
    "        y.append(data_lavel_dict[lavel])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b77ec9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.array(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f100f29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e55239",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1265a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941fa4cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7da6bbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f548184",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extractor(sample_frequency,x):\n",
    "    #sample_frequency = 360\n",
    "    fs = sample_frequency\n",
    "    t = np.arange(0,len(x))\n",
    "    tx = t/fs\n",
    "\n",
    "    #signal filtration and possible Peak detection\n",
    "    coeffs1 = pywt.wavedec(x,'sym4',level = 4,mode= 'periodic')\n",
    "    z0 = np.zeros(len(coeffs1[0]))\n",
    "    z1 = np.zeros(len(coeffs1[2]))\n",
    "    z3 = np.zeros(len(coeffs1[3]))\n",
    "    z4 = np.zeros(len(coeffs1[4]))\n",
    "\n",
    "    coeffs1[3] = z3\n",
    "    coeffs1[4] = z4\n",
    "\n",
    "    y1 = pywt.waverec(coeffs1,'sym4',mode = 'periodic')\n",
    "\n",
    "    avg1 = np.mean(abs(y1))\n",
    "\n",
    "    peaks1 = find_peaks(y1,height=avg1,distance = 50)\n",
    "\n",
    "    nop1 = peaks1[0]\n",
    "    posi1 = peaks1[1]\n",
    "    posi1 = posi1['peak_heights']\n",
    "\n",
    "    #applying wavelet transform\n",
    "    coeffs = pywt.wavedec(y1,'sym4',level = 4,mode = 'periodic')\n",
    "\n",
    "    #Removing some part of coefficient for proper R peak detection purpose\n",
    "    z1 = np.zeros(len(coeffs[0]))\n",
    "    z3 = np.zeros(len(coeffs[3]))\n",
    "    z4 = np.zeros(len(coeffs[4]))\n",
    "    coeffs[0] = z1\n",
    "    coeffs[3] = z3\n",
    "    coeffs[4] = z4\n",
    "\n",
    "    #reconstracting the signal\n",
    "    y = pywt.waverec(coeffs,'sym4',mode = 'periodic')\n",
    "\n",
    "    #finding the R_peaks from the reconstracted signal\n",
    "    avg = np.mean(abs(y))\n",
    "    peaks = find_peaks(y,height = avg*3,distance = 200)\n",
    "\n",
    "    nop = peaks[0]\n",
    "    posi = peaks[1]\n",
    "    posi = posi['peak_heights']\n",
    "    number_Rpeak = len(nop)\n",
    "\n",
    "    #Finding Number of beats per minute or Heartbeat\n",
    "    nump = len(nop)\n",
    "    time = len(x)/fs\n",
    "    nob = (nump*60)/time\n",
    "\n",
    "    #Original R peak and height\n",
    "    new_nop = []\n",
    "    for i in nop1:\n",
    "        for j in nop:\n",
    "            if abs(i-j)< 3:\n",
    "                new_nop.append(i)\n",
    "                continue\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "    r_real_height = []\n",
    "    for i in new_nop:\n",
    "        r_real_height.append(y1[i])\n",
    "\n",
    "    #finding height of R-peaks\n",
    "    avg_height = round(np.mean(r_real_height),2)\n",
    "    minimum_height = round(min(r_real_height),2)\n",
    "    maximum_height = round(max(r_real_height),2)\n",
    "\n",
    "    #finding peak width\n",
    "    results_half = peak_widths(y1, new_nop, rel_height=0.5)\n",
    "    width = results_half[0]\n",
    "\n",
    "    avrg_width = round(np.mean(width),2)\n",
    "    maximum_width = round(max(width),2)\n",
    "    minimum_width = round(min(width),2)\n",
    "\n",
    "    #finding R-R peak Distance\n",
    "    new_nop = np.array(new_nop)\n",
    "    nop_s = new_nop/fs\n",
    "    peak_dis = []\n",
    "\n",
    "    for i in range(len(nop_s)-1):\n",
    "        dis = abs(nop_s[i]-nop_s[i+1])\n",
    "        dis = round(dis,1)\n",
    "        peak_dis.append(dis)\n",
    "\n",
    "    avr_distance = round(np.mean(peak_dis),2)\n",
    "    max_distance = round(max(peak_dis),2)\n",
    "    min_distance = round(min(peak_dis),2)\n",
    "\n",
    "    #finding discontinuty\n",
    "    disc = []\n",
    "    for i in range(len(peak_dis)):\n",
    "        if 0.6 <= peak_dis[i] <= 1.2:\n",
    "            disc.append(0)\n",
    "        else:\n",
    "            disc.append(1)\n",
    "\n",
    "    if max(disc) == 1:\n",
    "        discontinuty = 1\n",
    "    else:\n",
    "        discontinuty = 0\n",
    "\n",
    "    #P-peaks detection\n",
    "    peaks_for_p = find_peaks(y1,height= 0*avg1,distance = 20)\n",
    "    nop_for_p = peaks_for_p[0]\n",
    "    posi_for_p = peaks_for_p[1]\n",
    "    posi_for_p = posi_for_p['peak_heights']\n",
    "\n",
    "    p_peaks = []\n",
    "    p_height = []\n",
    "    p_R_dis = []\n",
    "    nopp = new_nop\n",
    "\n",
    "    #def p_detection(p_value):\n",
    "\n",
    "    for i,n in enumerate(nopp):\n",
    "        #print('n = ',n)\n",
    "        #print('i = ',i)\n",
    "        for j,m in enumerate(nop_for_p):\n",
    "            #print('m = ',m)\n",
    "\n",
    "            if m == n:\n",
    "                #print('found equal')\n",
    "\n",
    "                if (j-1) < 0:\n",
    "                    k=j\n",
    "                elif (j-1) == 0:\n",
    "                    k = j-1\n",
    "                else:\n",
    "                    k = j-1\n",
    "                #print('not zero')\n",
    "                l = nop_for_p[k]\n",
    "                #print('l = ',l)\n",
    "\n",
    "\n",
    "                if (i-1) < 0:\n",
    "                    p=i\n",
    "                elif (i-1) == 0:\n",
    "                    p = i-1\n",
    "                else:\n",
    "                    p = i-1\n",
    "                #print('p = ',p)\n",
    "\n",
    "                for qw in range(10):\n",
    "                    if l != nopp[p]:\n",
    "                        #print(n-l)\n",
    "\n",
    "                        if (fs*0.12)-5 < n-l < (fs*0.20)+5:\n",
    "                            p_peaks.append(l)\n",
    "                            p_height.append(posi_for_p[k])\n",
    "                            p_R_dis.append(abs(n-l))\n",
    "                            break\n",
    "                        else:\n",
    "                            k = k-1\n",
    "                            l = nop_for_p[k]\n",
    "\n",
    "                    else:\n",
    "                        pass\n",
    "\n",
    "\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "    #finding Height of p_peaks\n",
    "    number_ppeaks = len(p_peaks)\n",
    "    max_height = round(max(p_height),2)\n",
    "    min_height = round(min(p_height),2)\n",
    "    avg_pheight = round(np.mean(p_height),2)\n",
    "\n",
    "    #P-R Interval or Distance\n",
    "    p_R_dis = np.array(p_R_dis)/fs\n",
    "    max_PR_dis = round(max(p_R_dis),2)\n",
    "    min_PR_dist = round(min(p_R_dis),2)\n",
    "    avg_PR_dis = round(np.mean(p_R_dis),2)\n",
    "\n",
    "    #QRS interval detection\n",
    "    r_y = -1*y1\n",
    "    avg2 = np.mean(abs(r_y))\n",
    "    QRS_peaks = find_peaks(r_y,height = -1*avg2*2,distance = 5)\n",
    "    QRS_nop1 = QRS_peaks[0]\n",
    "    QRS_posi = QRS_peaks[1]\n",
    "    QRS_posi = QRS_posi['peak_heights']\n",
    "\n",
    "    QRS_nop = np.append (QRS_nop1, new_nop)\n",
    "    QRS_nop.sort()\n",
    "\n",
    "    #QRS interval detection\n",
    "    Q_peaks = []\n",
    "    Q_hei = []\n",
    "    Q_dis = []\n",
    "    s_peaks = []\n",
    "    s_hei = []\n",
    "    s_dis = []\n",
    "    nopp = new_nop\n",
    "\n",
    "    for i,n in enumerate(nopp):\n",
    "        #print('n = ',n)\n",
    "        #print('i = ',i)\n",
    "        for j,m in enumerate(QRS_nop):\n",
    "            #print('m = ',m)\n",
    "\n",
    "            if m == n:\n",
    "                #print('found equal')\n",
    "\n",
    "                if (j-1) < 0:\n",
    "                    k=j\n",
    "                elif (j-1) == 0:\n",
    "                    k = j-1\n",
    "\n",
    "                else:\n",
    "                    k = j-1\n",
    "                #for s peak\n",
    "                if j+1 > len(QRS_nop):\n",
    "                    e = j\n",
    "                elif j+1 == len(QRS_nop):\n",
    "                    e = j\n",
    "                else:\n",
    "                    e = j+1\n",
    "\n",
    "                #print('not zero')\n",
    "                l = QRS_nop[k]\n",
    "                #print('l = ',l)\n",
    "                s = QRS_nop[e]\n",
    "\n",
    "\n",
    "                if (i-1) < 0:\n",
    "                    p=i\n",
    "                elif (i-1) == 0:\n",
    "                    p = i-1\n",
    "                else:\n",
    "                    p = i-1\n",
    "\n",
    "                #for s peak\n",
    "                if i+1 > len(nopp):\n",
    "                    g = i\n",
    "                elif i+1 == len(nopp):\n",
    "                    g = i\n",
    "                else:\n",
    "                    g = i+1\n",
    "                #print('p = ',p)  \n",
    "                if l != nopp[p]:\n",
    "                    #print(n-l)\n",
    "\n",
    "                    if n-l < 25:\n",
    "                        #print(\"p R =\",l,m)\n",
    "                        Q_peaks.append(l)\n",
    "                        Q_hei.append(y1[l])\n",
    "\n",
    "                    else:\n",
    "                        Q_peaks.append(n-8)\n",
    "                        Q_hei.append(0)\n",
    "                else:\n",
    "                    Q_peaks.append(n-8)\n",
    "                    Q_hei.append(0)\n",
    "\n",
    "                if s != nopp[g]:\n",
    "\n",
    "                    if abs(n-s) < 25:\n",
    "                        #print(\"p R =\",l,m)\n",
    "                        s_peaks.append(s)\n",
    "                        s_hei.append(y1[s])\n",
    "\n",
    "\n",
    "                    else:\n",
    "                        s_peaks.append(n+12)\n",
    "                        s_hei.append(0)\n",
    "                else:\n",
    "                    s_peaks.append(n+12)\n",
    "                    s_hei.append(0)\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "    q_peaks1 = np.array(Q_peaks)\n",
    "    S_peaks1 =np.array(s_peaks)\n",
    "    QRS_intervel = abs(S_peaks1 - q_peaks1 )\n",
    "\n",
    "    #finding Height of p_peaks\n",
    "    '''\n",
    "    s_hei\n",
    "    Q_hei\n",
    "    '''\n",
    "    avg_hei_s = round(np.mean(s_hei))\n",
    "    avg_hei_q = round(np.mean(Q_hei))\n",
    "\n",
    "    #QRS Interval or Distance\n",
    "    QRS_intervel = (QRS_intervel)/fs\n",
    "    max_QRS_dis = round(max(QRS_intervel),2)\n",
    "    min_QRS_dist = round(min(QRS_intervel),2)\n",
    "    avg_QRS_dis = round(np.mean(QRS_intervel),2)\n",
    "\n",
    "    #feature list\n",
    "    feature = [nob,maximum_height,minimum_height,avg_height,maximum_width,minimum_width,avrg_width,max_distance,min_distance,avr_distance,discontinuty,number_Rpeak,number_ppeaks,max_height,min_height,avg_pheight,max_PR_dis,min_PR_dist,avg_PR_dis,max_QRS_dis,min_QRS_dist,avg_QRS_dis,abs(avg_hei_s),abs(avg_hei_q)]\n",
    "    return(feature)\n",
    "    #feature = [nob,maximum_height,minimum_height,avg_height,maximum_width,minimum_width,avrg_width,max_distance,min_distance,avr_distance,discontinuty,max_height,min_height,avg_pheight,max_PR_dis,min_PR_dist,avg_PR_dis,max_QRS_dis,min_QRS_dist,avg_QRS_dis]\n",
    "    #return(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1624127",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(dataset[653])\n",
    "#plt.xlim(0,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a1488a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37256475",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b613e744",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set1 = dataset\n",
    "y1 = y\n",
    "x = []\n",
    "for i in range(len(dataset)):\n",
    "    f = feature_extractor(300,dataset[i])\n",
    "    #f = f[1:11]\n",
    "    #al = np.array(al)\n",
    "    #f.append(al)\n",
    "    #f = np.array(f)\n",
    "    x.append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb396f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f0c3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3eaf46",
   "metadata": {},
   "outputs": [],
   "source": [
    "x[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7b65c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(x[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84206a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3e956f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(x)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320863b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7c169e",
   "metadata": {},
   "source": [
    "# for detecting highest value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11624c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#flat = x.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb897ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#flat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2407d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b19bdea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#x = x.reshape(1542,11*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0adf1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcefb297",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.preprocessing import MinMaxScaler\n",
    "#mm = MinMaxScaler().fit(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559fe23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "stnd = StandardScaler().fit(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebbf134b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2fea3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = stnd.transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63716bba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41284ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d946fe17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "#y = to_cateorical(y)\n",
    "#g = to_categorical(y)\n",
    "#y = g\n",
    "#y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5fb46ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ccb076",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y,test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e327e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f412f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8969a989",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 2\n",
    "model1 = Sequential([\n",
    "    #layers.Normalization(axis=None),\n",
    "    layers.Dense(24,activation = 'relu'),\n",
    "    layers.Dense(15,activation = 'relu'),\n",
    "    layers.Dense(10,activation = 'relu'),\n",
    "    layers.Dense(10,activation = 'relu'),\n",
    "    layers.Dense(num_classes, activation = 'sigmoid')\n",
    "    \n",
    "])\n",
    "\n",
    "model1.compile(optimizer = 'adam',\n",
    "             loss=tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "                from_logits=True\n",
    "            ),\n",
    "             metrics = ['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11bf9607",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model1.fit(x_train, y_train, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3429572",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2b8a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = model1.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa53f01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted1 = np.round(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7d6938",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "predicted2 = []\n",
    "for i in range(len(predicted1)):\n",
    "    z = np.argmax(predicted1[i])\n",
    "    predicted2.append(z)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7657970c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix , classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2579d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,predicted2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5df26bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "cm = confusion_matrix(y_test,predicted2)\n",
    "sns.heatmap(cm,annot = True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1109140c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4f259f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.save('Model_big_data.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21227c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4d316f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23ce1ec",
   "metadata": {},
   "source": [
    "# Shuffeling dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e524a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c065d70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x2,y = shuffle(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc052d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x2[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ca1b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f202122b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def buid_classifier():\n",
    "    num_classes = 2\n",
    "    model1 = Sequential([\n",
    "        layers.Flatten(),\n",
    "        #layers.Normalization(axis=None),\n",
    "        layers.Dense(24,activation = 'relu'),\n",
    "        layers.Dense(15,activation = 'relu'),\n",
    "        layers.Dense(10,activation = 'relu'),\n",
    "        layers.Dense(10,activation = 'relu'),\n",
    "        layers.Dense(num_classes, activation = 'sigmoid')\n",
    "\n",
    "    ])\n",
    "\n",
    "    model1.compile(optimizer = 'adam',\n",
    "                 loss=tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "                    from_logits=True\n",
    "                ),\n",
    "                 metrics = ['accuracy'])\n",
    "    return model1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675182db",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = KerasClassifier(build_fn= buid_classifier, epochs = 100)\n",
    "accuracies = cross_val_score(estimator= classifiers, X= x2, y = y, cv = 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e60ee6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1f494d",
   "metadata": {},
   "outputs": [],
   "source": [
    "means = accuracies.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1233baaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a837a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17097fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6cf6a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d7e6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted1 = np.round(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c18062",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted2 = []\n",
    "for i in range(len(predicted1)):\n",
    "    z = np.argmax(predicted1[i])\n",
    "    predicted2.append(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af073865",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix , classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1076f20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,predicted2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b9cf84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "cm = confusion_matrix(y_test,predicted2)\n",
    "sns.heatmap(cm,annot = True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed0b121",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
